{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Introduction to Model Selection Methods </center>\n",
    "<br><br>\n",
    "<center> Zhangyi Hu </center>\n",
    "<center> Oct. 16, 2016</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# <center> Contents </center>\n",
    "\n",
    "- Review on basic terminology of statistical learning \n",
    "- Motivation of model selection\n",
    "- Three approaches of model selection\n",
    "    - Estimate test error\n",
    "    - Estimate information loss\n",
    "    - Estimate the posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Basic terminology of supervised statistical learning </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###  Data = feature + response "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Model  predicts response based on feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Data can be *Training* set or *Test* set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <center> Data = feature + response </center>\n",
    "Other names for *feature*:\n",
    "- regressor, predictor\n",
    "- independent(input, explanatory) variable\n",
    "- $X$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Other names for *response*:\n",
    "- regressand\n",
    "- dependent(output, explained) variable\n",
    "- $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <center> Model  predicts response based on feature </center>\n",
    "- Model is mathematically defined by a set of parameters $\\{\\theta_i\\}$\n",
    "  - Ture model: $\\mathbf{y}=f_{\\theta}\\left(\\mathbf{X}\\right)+\\mathbf{\\varepsilon}$\n",
    "  - Trained model:\n",
    "$\\hat{\\mathbf{y}}=g_{\\hat{\\theta}}\\left(\\mathbf{X}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The process of finding the value of parameters is called *Model Trainning*: \n",
    "$$\\{\\theta_{i}\\}\\rightarrow\\{\\hat{\\theta}_{i}\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The process of choosing the subset of parameter space is called *Model Selection*: \n",
    "$$\\{\\hat{\\theta}_{i}\\}_{i=1}^{p}\\mbox{ or }\\{\\hat{\\theta}_{i}\\}_{i=1}^{p+q}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <center> Training set and Test set </center>\n",
    "- Both are data, with feature and response\n",
    "- Training set is used to train the model, i.e. obtain $\\{\\theta_i\\}$\n",
    "  - The difference between model prediction and response in the training set: **Training Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Test set are used to evaluate the model\n",
    "  - Test set are usually not available to the model designer\n",
    "  - e.g. The the data provided by the end user of the trained model\n",
    "  - The difference between prediction and response in the test set: **Test Error**\n",
    "    - When the test set has the same features as training set but new observations of response: **In-sample Test Error**\n",
    "    - When the test set has different feature: **Extra-sample Test Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Usually, the model designer randomly put away part of available data and pretend he or she doesn't know it and, at the final stage, use it as test set\n",
    "- Generally, reducing *Test Error* is the main effort of statistical learning engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Motivation of model selection </center>\n",
    "### Model, by definition, need to be relatively simple to be practical\n",
    "### With no constraint on parameter space, a model can fit anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>One extreme example</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "matplotlib.rcParams.update({'font.size': 14})\n",
    "ax.set_xlabel('feature')\n",
    "ax.set_ylabel('response')\n",
    "ax.set_xlim([0.8, 6.0])\n",
    "ax.set_ylim([1.0, 9.0])\n",
    "x = [1,2,3,4]\n",
    "y = [2.1, 3.9, 6.0, 7.8]\n",
    "ax.plot(x, y, 'o', ms=8)\n",
    "for xy in zip(x, y):\n",
    "    ax.annotate(' (%s, %s)' % xy, xy=xy, textcoords='data') \n",
    "fig.savefig('resource/FourPoints.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src='resource/FourPoints.png' width='70%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center> A type of model that can fit any available data </center>\n",
    "<center> Its training error is zero! </center>\n",
    "<center> $y=\\begin{cases}\n",
    "2.1 & x=1\\\\\n",
    "3.9 & x=2\\\\\n",
    "6.0 & x=3\\\\\n",
    "7.8 & x=4\\\\\n",
    "x & \\mbox{otherwise}\n",
    "\\end{cases}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> Do we have a better model? </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Your brain just drew a straight line subconsciously \n",
    "#### It is the nature of intelligence to favor one simple line compared with 4 points\n",
    "#### Artificial Intelligence behaviors in a similar way\n",
    "#### The purpose of model selection is find a proper constraint on the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Examples of model parameter Constraints </center>\n",
    "Let the parameters be a $p$-vector $\\mathbf{\\beta} = [\\beta_1,\\dots,\\beta_p]^T$\n",
    "\n",
    "- $\\left\\Vert \\mathbf{\\beta}\\right\\Vert _{0} \\le n$, subset selection\n",
    "- $\\left\\Vert \\mathbf{\\beta}\\right\\Vert _{1} \\le \\lambda$, LASSO\n",
    "- $\\left\\Vert \\mathbf{\\beta}\\right\\Vert _{2} \\le \\lambda$, Shrinkage\n",
    "\n",
    "Model selection find the suitable $n$ or $\\lambda$, which defines a subset of the parameter space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Three approaches of model selection</center>\n",
    "#### Estimate test error (Mallow's $C_p$, Cross validation, Bootstrap)\n",
    "#### Estimate information loss (Akaike Information Criterion)\n",
    "#### Estimate the posterior probability (Bayesian Information Criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <center>Test error function</center>\n",
    "- Test error(or loss) function measures how bad a prediction is with test data:\n",
    "\n",
    "<center>e.g. squared-error loss: $L(y,\\hat{y})=\\left(y-\\hat{y}\\right)^{2}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### <center>Decomposition of expected test error</center>\n",
    "\n",
    "\\begin{align*}\n",
    "\\mbox{Err}\\left(x_{0}\\right) & =\\mathbb{E}\\left[(Y-\\hat{f}(x_{0}))^{2}\\right]\\\\\n",
    " & =\\mathbb{E}\\left[\\left(f(x_{0})+\\varepsilon-\\hat{f}(x_{0})\\right)^{2}\\right]\\\\\n",
    " & =\\sigma_{\\varepsilon}^{2}+\\mathbb{E}\\left[\\left(f(x_{0})-\\mathbb{E}\\left[\\hat{f}(x_{0})\\right]+\\mathbb{E}\\left[\\hat{f}(x_{0})\\right]-\\hat{f}(x_{0})\\right)^{2}\\right]\\\\\n",
    " & =\\sigma_{\\varepsilon}^{2}+\\mathbb{E}\\left[\\left(f(x_{0})-\\mathbb{E}\\left[\\hat{f}(x_{0})\\right]\\right)^{2}\\right]+\\mathbb{E}\\left[\\left(\\mathbb{E}\\left[\\hat{f}(x_{0})\\right]-\\hat{f}(x_{0})\\right)^{2}\\right]\\\\\n",
    " & =\\sigma_{\\varepsilon}^{2}+\\mbox{Bias}^{2}\\left(f(x_{0})\\right)+\\mbox{Var}\\left(\\hat{f}(x_{0})\\right)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Bias-Variance trade off </center>\n",
    "- With model getting more complex, the bias usually decreases\n",
    "- However, at the same time the variance usually goes up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- e.g. in OLS\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\mbox{Var}\\left(\\hat{f}(x_{i})\\right) & = & \\frac{p}{N}\\sigma_{\\varepsilon}^{2}\\\\\n",
    "\\mbox{Var}\\left(\\hat{f}(x_{0})\\right) & \\sim & \\frac{p}{N}\\sigma_{\\varepsilon}^{2},\\quad N\\rightarrow\\infty\n",
    "\\end{eqnarray*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "$\\begin{array}{cc}\n",
    "x_{i} & x_{0}\\\\\n",
    "\\overline{\\mbox{in sample}} & \\overline{\\mbox{out of sample}}\n",
    "\\end{array}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Bias-Variance trade off </center>\n",
    "- Training error always decreases with increasingly complex model(or with more fitting effort)\n",
    "- It is a common mistake to use too complex a model with large variance: **over fit**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center> Perhaps the most over fitted model </center>\n",
    "\n",
    "<center> $y=\\begin{cases}\n",
    "y_i & \\mathrm{if}\\quad x=x_i\\\\\n",
    "x & \\mbox{otherwise}\n",
    "\\end{cases}$ </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Bias-Variance trade off </center>\n",
    "<center><img src='resource/ESLII_Fig7.2.png' width='60%'/></center>\n",
    "<center><font size=\"3\">T. Hastie, R. Tibshirani, and J. Friedman, Elements of statistical learning, Figure 7.2</font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Estimate test error</center>\n",
    "- Select the subset of parameter space whose best fitted model produces the smallest test error\n",
    "\n",
    "- With many loss functions, the difference between in sample test error and training error plus some term can be caculated explicitly\n",
    "$$\\mathbb{E}_{\\mathbf{y}}\\left[\\mbox{Err}_{\\mbox{in}}\\right]=\\mathbb{E}_{\\mathbf{y}}\\left[\\overline{\\mbox{err}}\\right]+\\frac{2}{N}\\sum_{i=1}^{N}\\mathrm{Cov}\\left(\\hat{y}_{i},y_{i}\\right)$$\n",
    "\n",
    "- <a href='http://nbviewer.jupyter.org/github/hzzyyy/Presentations/blob/master/Model%20Selection/proofs/In-sample%20test%20error%20and%20training%20error.ipynb'>Proof for squared error loss function </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Mallow's $C_p$ </center>\n",
    "- Mallow's $C_p$ estimates in-sample test error for OLS\n",
    "- Let's denote the projection matrix of OLS as:\n",
    "$$\\mathbf{S}=\\mathbf{X}\\left(\\mathbf{X}^{T}\\mathbf{X}\\right)^{-1}\\mathbf{X}^{T}$$\n",
    "- Then we can prove that:\n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{i=1}^{N}\\mbox{Cov}\\left(\\hat{y}_{i},y_{i}\\right) & =\\sigma_{\\varepsilon}^{2}\\mbox{Tr}\\left(\\mathbf{S}\\right)=\\sigma_{\\varepsilon}^{2}p\n",
    "\\end{align*}\n",
    "$$\\mathbb{E}_{\\mathbf{y}}\\left[\\mbox{Err}_{\\mbox{in}}\\right]=\\mathbb{E}_{\\mathbf{y}}\\left[\\overline{\\mbox{err}}\\right]+\\frac{2p}{N}\\sigma_{\\varepsilon}^{2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center> Mallow's $C_p$ </center>\n",
    "- Mallow's $C_p$ estimates in-sample test error for OLS\n",
    "- $\\frac{\\mbox{RSS}}N$ estimates $\\mathbb{E}_{\\mathbf{y}}\\left[\\mbox{Err}_{\\mbox{in}}\\right]$\n",
    "- $\\sigma_{\\varepsilon}^2$ is estimated from another low bias model, which is most likely overfitted\n",
    "- In subset selection\n",
    "$C_{p}=\\frac{\\mbox{RSS}_{p}}{N}+\\frac{2p}{N}\\frac{\\mbox{RSS}_{K}}{N-K}$\n",
    "- In OLS, extra-sample test error approaches in-sample test error \n",
    "as $N$ gets large (<a href='http://nbviewer.jupyter.org/github/hzzyyy/Presentations/blob/master/Model%20Selection/proofs/In-sample%20test%20error%20and%20extra-sample%20test%20error.ipynb'>proof</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Estimate test error</center>\n",
    "- We can also directly estimate extra-sample test error, by using part of the training set as \"test set\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is not the real test, because test set is used at the final stage, after the model selection is completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is not used in model training with given parameter space constraint, so it is not training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- It is in between training set and test set and we name it **validation set**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## <center>Estimate test error</center>\n",
    "| <font size='5'>Training set </font>|<font size='5'> Validation set </font>|\n",
    "| :-----------------: | :------------: |\n",
    "| $\\mathcal{T}$ | $\\mathcal{V} = \\{(x^j, y^j)\\}_{j=1}^{M} $ |\n",
    "- With one random partition between training and validation set, \n",
    "we can obtain one realization of the mean extra-sample test error\n",
    "$$\\frac{1}{M}\\sum_{j=1}^{M}L(y^{j},\\hat{y}^{j})$$\n",
    "- This is one realization of the moment estimator of the expected extra-sample test error\n",
    "$$\\mbox{Err}_{\\mathcal{T}}=\\mathbb{E}_{y^j}\\left[L(y^{j},\\hat{y}^{j})\\vert\\mathcal{T}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- If we use only one such realization to estimate, the variance is too large. \n",
    "By central limit theorem, we can use the mean of $K$ such realizations to reduce the variance by a factor of $1/K$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| <font size='5'>Training sets </font>|<font size='5'> Validation sets </font>|\n",
    "| :-----------------: | :------------: |\n",
    "| $\\mathcal{T}_1$ | $\\mathcal{V}_1 = \\{(x_1^j, y_1^j)\\}_{j=1}^{M} $ |\n",
    "| $\\cdots$ | $\\cdots$ |\n",
    "| $\\mathcal{T}_i$ | $\\mathcal{V}_i = \\{(x_i^j, y_i^j)\\}_{j=1}^{M} $ |\n",
    "| $\\cdots$ | $\\cdots$ |\n",
    "| $\\mathcal{T}_K$ | $\\mathcal{V}_K = \\{(x_K^j, y_K^j)\\}_{j=1}^{M} $ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The mean of the $K$ means of the extra-sample test error is\n",
    "$$\\frac{1}{K}\\sum_{i=1}^{K}\\frac{1}{M}\\sum_{j=1}^{M}L(y_{i}^{j},\\hat{y}_{i}^{j})$$\n",
    "- Which is a moment estimator of the iterated expected extra-sample test error\n",
    "$$\\mbox{Err}=\\mathbb{E}_{\\mathcal{T}}\\left[\\mbox{Err}_{\\mathcal{T}}\\right]=\\mathbb{E}_{\\mathcal{T}}\\left[\\mathbb{E}_{y^{j}}\\left[L(y^{j},\\hat{y}^{j})\\vert\\mathcal{T}\\right]\\right]$$\n",
    "- There are two sources of randomness\n",
    " - realization of the random test response $y_i^j$, conditional on $\\mathcal{T}_i$\n",
    " - realization of the random partition between $\\mathcal{T}_i$ and $\\mathcal{V}_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Cross validation </center> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!-- enlarge the font size to suit slide show -->\n",
       "<style>\n",
       "    div.output_result {\n",
       "    font-size:150%;\n",
       "    line-height:150%;\n",
       "    }\n",
       "    \n",
       "    div.output_stdout { \n",
       "    font-size:150%;\n",
       "    line-height:150%;\n",
       "    }\n",
       "\n",
       "    div.prompt { /* hidden by the js block at the end */\n",
       "    font-size:100%;\n",
       "    line-height:100%;\n",
       "    }\n",
       "\n",
       "    div.CodeMirror { /* Code cell */\n",
       "    font-size:150%;\n",
       "    line-height:150%;\n",
       "    }\n",
       "    \n",
       "    div.text_cell_render { /* Markdown cell */\n",
       "    font-family: 'Times New Roman';\n",
       "    font-size:150%;\n",
       "    line-height:150%;\n",
       "    }\n",
       "</style>\n",
       "\n",
       "<!-- hide elements on the left to center the slides -->\n",
       "<script>\n",
       "    $(document).ready(function(){\n",
       "        $('div.prompt').hide();\n",
       "        $('div.back-to-top').hide();\n",
       "        $('nav#menubar').hide();\n",
       "        $('.breadcrumb').hide();\n",
       "        $('.hidden-print').hide();\n",
       "    });\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename='../slides.html')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:slides]",
   "language": "python",
   "name": "conda-env-slides-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {
    "05a8dbeb-d54c-4e49-aafc-68b7e45719fd": {
     "id": "05a8dbeb-d54c-4e49-aafc-68b7e45719fd",
     "prev": "b9c9fcc5-51b0-4da4-8416-f11c87a438c5",
     "regions": {
      "746ce7f4-633e-40ed-9961-559d5ab3bd47": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "746ce7f4-633e-40ed-9961-559d5ab3bd47"
      }
     }
    },
    "2388de70-ea9e-414d-b2cc-190a1e7b207a": {
     "id": "2388de70-ea9e-414d-b2cc-190a1e7b207a",
     "prev": "b0c6975e-4388-4e12-b61c-8d3bcee65fed",
     "regions": {
      "bef4757c-eb56-4cf3-a9c9-c05105c9c739": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "ef9df2b8-dd9c-49ba-b489-f7c0cef59906",
        "part": "whole"
       },
       "id": "bef4757c-eb56-4cf3-a9c9-c05105c9c739"
      }
     }
    },
    "43fc8132-b51d-4250-ab14-f1a5d2d5c36c": {
     "id": "43fc8132-b51d-4250-ab14-f1a5d2d5c36c",
     "prev": "2388de70-ea9e-414d-b2cc-190a1e7b207a",
     "regions": {
      "20f99b9a-644f-48ee-993c-8db67a607b67": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "20f99b9a-644f-48ee-993c-8db67a607b67"
      }
     }
    },
    "4bbf284f-80a5-40b7-b5fd-bcaec92e3afb": {
     "id": "4bbf284f-80a5-40b7-b5fd-bcaec92e3afb",
     "prev": "50eef625-1642-40a3-86a6-910695eb4410",
     "regions": {
      "3ef03aea-6e04-40a6-93ce-8817e73ac289": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "3ef03aea-6e04-40a6-93ce-8817e73ac289"
      }
     }
    },
    "50eef625-1642-40a3-86a6-910695eb4410": {
     "id": "50eef625-1642-40a3-86a6-910695eb4410",
     "prev": "43fc8132-b51d-4250-ab14-f1a5d2d5c36c",
     "regions": {
      "b434ef4e-3f8c-4d4e-a275-5c0c2d398017": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "b434ef4e-3f8c-4d4e-a275-5c0c2d398017"
      }
     }
    },
    "57fb394f-5e64-48e7-92a5-3208563cf1c6": {
     "id": "57fb394f-5e64-48e7-92a5-3208563cf1c6",
     "prev": "6c97ab4a-63cf-4509-9b70-5742e5df8d3b",
     "regions": {
      "3a6522b3-be6b-4d37-b920-fc5f68c0db11": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "3a6522b3-be6b-4d37-b920-fc5f68c0db11"
      }
     }
    },
    "6c97ab4a-63cf-4509-9b70-5742e5df8d3b": {
     "id": "6c97ab4a-63cf-4509-9b70-5742e5df8d3b",
     "prev": "4bbf284f-80a5-40b7-b5fd-bcaec92e3afb",
     "regions": {
      "cb9d2e9a-a5c8-4abb-b62f-624acaad7b75": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "cb9d2e9a-a5c8-4abb-b62f-624acaad7b75"
      }
     }
    },
    "b0c6975e-4388-4e12-b61c-8d3bcee65fed": {
     "id": "b0c6975e-4388-4e12-b61c-8d3bcee65fed",
     "prev": "f9c1903a-c098-48bf-a8c7-b324a34d9af4",
     "regions": {
      "f1ebc62d-e674-47d7-9f1b-b40dab0fab4a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3e13915c-3e50-4d97-92af-dc493d409193",
        "part": "whole"
       },
       "id": "f1ebc62d-e674-47d7-9f1b-b40dab0fab4a"
      }
     }
    },
    "b9c9fcc5-51b0-4da4-8416-f11c87a438c5": {
     "id": "b9c9fcc5-51b0-4da4-8416-f11c87a438c5",
     "prev": "57fb394f-5e64-48e7-92a5-3208563cf1c6",
     "regions": {
      "f0317884-d843-42fb-bb7e-c2b96698812a": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "cd6f0a2a-2288-4cf2-a060-7f3e818a3a66",
        "part": "whole"
       },
       "id": "f0317884-d843-42fb-bb7e-c2b96698812a"
      }
     }
    },
    "f9c1903a-c098-48bf-a8c7-b324a34d9af4": {
     "id": "f9c1903a-c098-48bf-a8c7-b324a34d9af4",
     "prev": null,
     "regions": {
      "5a039c08-01d5-4a10-b2ed-04bb7679890f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f4e8d878-6137-4252-898b-dbfa915dec9b",
        "part": "whole"
       },
       "id": "5a039c08-01d5-4a10-b2ed-04bb7679890f"
      }
     }
    }
   },
   "themes": {
    "default": "03b5650f-0d59-4991-a7b0-447a9541a40c",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
